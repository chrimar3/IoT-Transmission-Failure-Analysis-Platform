# Story 2.4: Rate Limiting by Subscription Tier

## Status
Draft

## Story
**As a** system administrator,
**I want** API rate limiting enforced based on subscription tier,
**so that** free users don't overwhelm system resources while Professional subscribers receive priority access and performance.

## Acceptance Criteria
1. Free tier users limited to 100 API requests per hour with clear rate limit headers
2. Professional tier users allowed 10,000 API requests per hour with burst capabilities
3. Rate limit headers included in all API responses (X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset)
4. Clear, user-friendly error messages when rate limits are exceeded with upgrade prompts
5. Redis-based distributed rate limiting for horizontal scalability across serverless functions
6. Rate limit enforcement integrated with tiered access control middleware from Story 2.3
7. Rate limit bypass mechanism for internal operations and health checks
8. Rate limit monitoring with automated alerts at 80% threshold approaching limits
9. Graceful fallback mechanisms when Redis is unavailable with local caching
10. Real-time rate limit status updates based on subscription tier changes from Stripe webhooks

## Priority & Effort
**Priority**: P1 (Performance - Resource Protection)
**Effort**: 3 points
**Epic**: Epic 2 - User Authentication & Subscription Management

## Tasks / Subtasks
- [ ] Implement Redis-based distributed rate limiting middleware (AC: 1,2,5,9)
  - [ ] Set up Redis client configuration in `/src/lib/redis.ts` with connection pooling
  - [ ] Create rate limiting middleware in `/src/middleware/rateLimiting.ts` with sliding window algorithm
  - [ ] Implement tier-based rate limit configuration (100/hour free, 10,000/hour professional)
  - [ ] Add Redis key management with TTL and automatic cleanup
  - [ ] Create fallback in-memory rate limiting when Redis is unavailable
  - [ ] Add connection retry logic with exponential backoff for Redis failures
- [ ] Integrate rate limiting with subscription tier validation (AC: 6,10)
  - [ ] Extend subscription access checking from Story 2.3 to include rate limits
  - [ ] Add real-time subscription tier updates via Stripe webhook integration
  - [ ] Create rate limit tier mapping in `/src/lib/subscription-access.ts`
  - [ ] Implement subscription-based rate limit key generation (user_id + tier)
  - [ ] Add cache invalidation for rate limits on subscription tier changes
  - [ ] Create automatic rate limit adjustment on subscription upgrades/downgrades
- [ ] Add comprehensive rate limit headers and API responses (AC: 3,4)
  - [ ] Implement standard rate limiting headers in all API responses
  - [ ] Create user-friendly rate limit exceeded error responses with upgrade CTAs
  - [ ] Add rate limit status endpoint `/src/app/api/rate-limit/status/route.ts`
  - [ ] Create rate limit remaining indicators for dashboard UI
  - [ ] Add progressive warning messages as users approach limits
  - [ ] Implement client-side rate limit awareness with retry logic
- [ ] Create rate limit monitoring and bypass mechanisms (AC: 7,8)
  - [ ] Implement internal operations bypass with API key authentication
  - [ ] Add rate limit monitoring dashboard for administrators
  - [ ] Create automated alerts at 80% rate limit threshold via webhook
  - [ ] Add rate limit analytics and usage tracking per user
  - [ ] Implement health check endpoints with rate limit bypass
  - [ ] Create rate limit abuse detection and automatic protection
- [ ] Add comprehensive testing suite for rate limiting functionality (AC: All)
  - [ ] Unit tests for rate limiting middleware with various scenarios
  - [ ] Integration tests for Redis integration with connection failures
  - [ ] Performance tests for rate limiting overhead (<50ms per request)
  - [ ] Load testing with concurrent users at various subscription tiers
  - [ ] Security testing for rate limit bypass attempts and manipulation
  - [ ] End-to-end testing for complete rate limiting flows with UI feedback

## Dev Notes

### Previous Story Insights
Building the rate limiting layer that integrates with and protects the foundation established by:
- **Story 2.1**: NextAuth.js authentication provides secure user session identification for rate limiting
- **Story 2.2**: Stripe subscription integration provides subscription tier for rate limit determination
- **Story 2.3**: Tiered access control middleware provides subscription tier validation and caching
- **Story 1.4**: Core API endpoints require protection from abuse with tier-appropriate rate limits
- **Story 1.2**: Database schema provides subscription tracking for tier-based rate limiting

This story creates the critical performance protection layer that prevents system abuse while ensuring Professional subscribers receive premium service quality through higher rate limits.

### Data Models
[Source: architecture/7-database-schema-bangkok-dataset-optimized.md]

**Rate Limiting Schema Extensions**: Building on existing subscriptions table
```sql
-- Extended subscriptions table for rate limiting
ALTER TABLE subscriptions ADD COLUMN IF NOT EXISTS:
  rate_limit_tier INTEGER DEFAULT 100,     -- Requests per hour limit
  rate_limit_reset TIMESTAMPTZ DEFAULT NOW(), -- Rate limit window reset time
  rate_limit_used INTEGER DEFAULT 0,      -- Current period usage
  burst_allowance INTEGER DEFAULT 10,     -- Burst request allowance
  last_request_time TIMESTAMPTZ DEFAULT NOW() -- Last API request timestamp
```

**Rate Limiting Audit Table**: New table for monitoring and compliance
```sql
CREATE TABLE rate_limit_audit (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES auth.users(id),
    api_endpoint VARCHAR(200) NOT NULL,     -- Specific endpoint accessed
    subscription_tier VARCHAR(20) NOT NULL, -- User's tier at time of request
    request_count INTEGER NOT NULL,         -- Current request count in window
    rate_limit_hit BOOLEAN NOT NULL,        -- Whether rate limit was exceeded
    response_time_ms INTEGER,               -- API response time
    ip_address INET,                        -- Request IP for abuse detection
    user_agent TEXT,                        -- Request user agent
    created_at TIMESTAMPTZ DEFAULT NOW(),
    
    -- Indexes for performance
    INDEX idx_rate_audit_user_time (user_id, created_at),
    INDEX idx_rate_audit_endpoint_time (api_endpoint, created_at),
    INDEX idx_rate_audit_rate_limit (rate_limit_hit, created_at)
);
```

**Rate Limit Configuration**: Tier-based limits with burst handling
- **Free Tier Rate Limits**: 
  - Base limit: 100 requests/hour (sliding window)
  - Burst allowance: 10 additional requests/minute for brief spikes
  - Warning threshold: 80% of limit (80 requests) with user notification
  - Reset behavior: Sliding window, not fixed hourly reset
- **Professional Tier Rate Limits**: 
  - Base limit: 10,000 requests/hour with room for growth
  - Burst allowance: 200 additional requests/minute for high-frequency usage
  - Warning threshold: 90% of limit (9,000 requests) with monitoring alert
  - Priority handling: Separate queue processing for professional users

### API Specifications
[Source: architecture/8-api-architecture.md]

**Rate Limiting Integration with Existing API Architecture**:
```typescript
// Enhanced API endpoint with rate limiting
export async function GET(request: NextRequest) {
  const session = await getServerSession(authOptions);
  if (!session) return unauthorizedResponse();
  
  // Check subscription tier and rate limits
  const rateLimitResult = await checkRateLimit(
    session.user.id,
    request.nextUrl.pathname
  );
  
  if (!rateLimitResult.allowed) {
    return NextResponse.json({
      error: 'Rate limit exceeded',
      message: `You have exceeded your ${rateLimitResult.tierName} tier rate limit`,
      rateLimitInfo: {
        limit: rateLimitResult.limit,
        remaining: rateLimitResult.remaining,
        resetTime: rateLimitResult.resetTime,
        upgradeUrl: rateLimitResult.tierName === 'free' ? '/subscription/upgrade' : null
      }
    }, {
      status: 429,
      headers: {
        'X-RateLimit-Limit': rateLimitResult.limit.toString(),
        'X-RateLimit-Remaining': rateLimitResult.remaining.toString(),
        'X-RateLimit-Reset': rateLimitResult.resetTime.toString(),
        'Retry-After': rateLimitResult.retryAfter.toString()
      }
    });
  }
  
  // Continue with business logic...
  const response = await processApiRequest(request);
  
  // Add rate limit headers to successful responses
  response.headers.set('X-RateLimit-Limit', rateLimitResult.limit.toString());
  response.headers.set('X-RateLimit-Remaining', (rateLimitResult.remaining - 1).toString());
  response.headers.set('X-RateLimit-Reset', rateLimitResult.resetTime.toString());
  
  return response;
}
```

**Rate Limiting API Endpoints**:
- GET /api/rate-limit/status - Current rate limit status with remaining requests
- GET /api/rate-limit/usage - Historical usage patterns and analytics (admin only)
- POST /api/rate-limit/bypass - Temporary bypass for internal operations (API key auth)
- GET /api/rate-limit/health - Health check endpoint with rate limit bypass

**Redis Integration for Distributed Rate Limiting**:
```typescript
// Redis-based sliding window rate limiting
export interface IRateLimitResult {
  allowed: boolean;
  limit: number;
  remaining: number;
  resetTime: number;
  retryAfter?: number;
  tierName: string;
}

export const checkRateLimit = async (
  userId: string,
  endpoint: string
): Promise<IRateLimitResult> => {
  const subscriptionTier = await getSubscriptionTier(userId);
  const limit = getRateLimitForTier(subscriptionTier);
  const key = `rate_limit:${userId}:${subscriptionTier}`;
  const window = 3600; // 1 hour in seconds
  
  try {
    // Redis sliding window algorithm
    const pipeline = redisClient.pipeline();
    const now = Date.now();
    const windowStart = now - (window * 1000);
    
    pipeline.zremrangebyscore(key, '-inf', windowStart);
    pipeline.zcard(key);
    pipeline.zadd(key, now, now);
    pipeline.expire(key, window);
    
    const results = await pipeline.exec();
    const requestCount = results[1][1] as number;
    
    return {
      allowed: requestCount < limit,
      limit,
      remaining: Math.max(0, limit - requestCount),
      resetTime: Math.ceil((now + (window * 1000)) / 1000),
      tierName: subscriptionTier,
      retryAfter: requestCount >= limit ? calculateRetryAfter(key) : undefined
    };
  } catch (redisError) {
    // Fallback to in-memory rate limiting
    console.warn('Redis unavailable, falling back to memory-based rate limiting:', redisError);
    return await fallbackRateLimit(userId, endpoint, limit);
  }
};
```

### Component Specifications
[Source: architecture/source-tree.md, architecture/coding-standards.md]

**Rate Limiting Infrastructure Components**:
```typescript
// src/lib/redis.ts - Redis client configuration
export const redisClient = new Redis({
  host: process.env.REDIS_HOST || 'localhost',
  port: parseInt(process.env.REDIS_PORT || '6379'),
  password: process.env.REDIS_PASSWORD,
  retryDelayOnFailover: 100,
  maxRetriesPerRequest: 3,
  lazyConnect: true,
});

// src/middleware/rateLimiting.ts - Rate limiting middleware
export interface IRateLimitConfig {
  free: { requests: 100, window: 3600, burst: 10 };
  professional: { requests: 10000, window: 3600, burst: 200 };
}

export const rateLimitingMiddleware = async (
  request: NextRequest,
  userId: string,
  subscriptionTier: string
): Promise<IRateLimitResult> => {
  // Implementation with sliding window algorithm and Redis backend
};
```

**Rate Limit Status Components**:
```typescript
// src/components/features/rate-limit/RateLimitIndicator.tsx
interface IRateLimitIndicatorProps {
  current: number;
  limit: number;
  resetTime: number;
  tier: 'free' | 'professional';
}

export const RateLimitIndicator: React.FC<IRateLimitIndicatorProps> = ({
  current,
  limit,
  resetTime,
  tier
}) => {
  const percentage = (current / limit) * 100;
  const isNearLimit = percentage > 80;
  const resetDate = new Date(resetTime * 1000);
  
  return (
    <div className={cn('rate-limit-indicator', isNearLimit && 'warning')}>
      <div className="flex justify-between items-center">
        <span className="text-sm text-gray-600">
          API Requests: {current.toLocaleString()} / {limit.toLocaleString()}
        </span>
        {tier === 'free' && isNearLimit && (
          <Link href="/subscription/upgrade" className="text-blue-600 text-sm">
            Upgrade for Higher Limits
          </Link>
        )}
      </div>
      
      <div className="w-full bg-gray-200 rounded-full h-2 mt-2">
        <div
          className={cn(
            'h-2 rounded-full transition-all',
            percentage < 70 ? 'bg-green-500' : 
            percentage < 90 ? 'bg-yellow-500' : 'bg-red-500'
          )}
          style={{ width: `${Math.min(percentage, 100)}%` }}
        />
      </div>
      
      <p className="text-xs text-gray-500 mt-1">
        Resets at {resetDate.toLocaleTimeString()}
      </p>
    </div>
  );
};
```

**Rate Limit Hook for Real-time Updates**:
```typescript
// src/hooks/useRateLimit.ts
export const useRateLimit = () => {
  const [rateLimitStatus, setRateLimitStatus] = useState<IRateLimitResult | null>(null);
  const [isLoading, setIsLoading] = useState(true);
  const { data: session } = useSession();

  useEffect(() => {
    const fetchRateLimitStatus = async () => {
      if (!session?.user?.id) return;
      
      try {
        const response = await fetch('/api/rate-limit/status');
        const data = await response.json();
        setRateLimitStatus(data);
      } catch (error) {
        console.error('Failed to fetch rate limit status:', error);
      } finally {
        setIsLoading(false);
      }
    };

    fetchRateLimitStatus();
    
    // Poll for updates every 30 seconds
    const interval = setInterval(fetchRateLimitStatus, 30000);
    return () => clearInterval(interval);
  }, [session?.user?.id]);

  return {
    rateLimitStatus,
    isLoading,
    isNearLimit: rateLimitStatus ? (rateLimitStatus.remaining / rateLimitStatus.limit) < 0.2 : false,
    refreshStatus: fetchRateLimitStatus
  };
};
```

### File Locations
[Source: architecture/source-tree.md]

**Core Rate Limiting Infrastructure**:
- `/src/lib/redis.ts` - Redis client configuration with connection handling
- `/src/lib/rate-limiting.ts` - Rate limiting utilities and algorithms
- `/src/middleware/rateLimiting.ts` - Express/Next.js rate limiting middleware
- `/src/types/rate-limiting.ts` - TypeScript types for rate limiting interfaces

**API Endpoints for Rate Limiting**:
- `/src/app/api/rate-limit/status/route.ts` - Current rate limit status endpoint
- `/src/app/api/rate-limit/usage/route.ts` - Usage analytics and monitoring
- `/src/app/api/rate-limit/bypass/route.ts` - Internal operations bypass
- `/src/app/api/rate-limit/health/route.ts` - Health check with bypass

**React Components for Rate Limit Management**:
- `/src/components/features/rate-limit/RateLimitIndicator.tsx` - Rate limit status display
- `/src/components/features/rate-limit/RateLimitWarning.tsx` - Warning messages component
- `/src/components/features/rate-limit/UpgradePromptModal.tsx` - Rate limit upgrade prompts
- `/src/components/features/rate-limit/UsageChart.tsx` - Usage visualization component

**Hooks and Utilities**:
- `/src/hooks/useRateLimit.ts` - Rate limit status management hook
- `/src/hooks/useApiWithRateLimit.ts` - API requests with rate limit awareness
- `/src/utils/rateLimitHelpers.ts` - Rate limiting calculation utilities

**Tests**:
- `/__tests__/lib/rate-limiting.test.ts` - Core rate limiting logic tests
- `/__tests__/middleware/rateLimiting.test.ts` - Middleware integration tests
- `/__tests__/api/rate-limit/` - Rate limiting API endpoint tests
- `/__tests__/components/rate-limit/` - Rate limit UI component tests

### Technical Constraints
[Source: architecture/tech-stack.md, architecture/8-api-architecture.md]

**Performance Requirements**:
- Rate limiting check overhead: <50ms per API request (95th percentile)
- Redis operation timeout: 100ms maximum with fallback
- Memory-based fallback: <10ms when Redis unavailable
- Database rate limit audit: Asynchronous logging with batch inserts

**Redis Configuration Requirements**:
- Redis connection pooling: 10 connections minimum for high concurrency
- Redis persistence: RDB snapshots + AOF logging for data durability
- Redis clustering: Single instance sufficient for MVP, clustering for scale
- Redis memory optimization: LRU eviction policy for rate limit data

**Scalability Constraints**:
- **Vercel Functions**: 10-second execution limit, stateless design required
- **Redis Memory**: Efficient key naming and TTL for automatic cleanup
- **Concurrent Users**: 1000+ simultaneous rate limit checks supported
- **Database Logging**: Batch audit log inserts to prevent database overload

**Integration Requirements**:
- **NextAuth.js**: User identification for rate limiting keys
- **Stripe Webhooks**: Real-time tier changes affect rate limits immediately
- **Middleware Integration**: Seamless integration with Story 2.3 access control
- **API Response Headers**: Standard rate limiting headers for client libraries

### Testing Requirements
[Source: architecture/5-testing-framework-setup-installation.md]

**Test Coverage Requirements**:
- 100% coverage for rate limiting core logic and algorithms
- 100% coverage for Redis integration with failure scenarios
- 85% minimum coverage for rate limit UI components and hooks
- Integration testing with various subscription tiers and concurrent users

**Testing Frameworks and Patterns**:
- Jest for unit testing with Redis mocking via redis-memory-server
- React Testing Library for rate limit indicator and warning components
- Supertest for API endpoint rate limiting with simulated high traffic
- Artillery or similar for load testing rate limiting performance

**Specific Testing Requirements**:
- Sliding window algorithm accuracy with time-based scenarios
- Redis connection failure handling and fallback mechanisms
- Subscription tier changes and immediate rate limit updates
- Concurrent user rate limiting with race condition testing
- Performance testing for <50ms rate limit check requirement
- Security testing for rate limit bypass attempts and manipulation

**Test Data and Scenarios**:
- Mock users with different subscription tiers and usage patterns
- Simulated high-traffic scenarios approaching rate limits
- Redis failure scenarios with fallback validation
- Time zone and daylight saving time effects on sliding windows
- Burst request handling and recovery scenarios

### Production Readiness Requirements

**Monitoring and Alerting**:
- Rate limit usage monitoring with automated threshold alerts (80% capacity)
- Redis performance and availability monitoring with uptime tracking
- Subscription tier change monitoring with rate limit adjustment validation
- API endpoint abuse detection with automatic protection mechanisms

**Error Handling and Recovery**:
- Graceful degradation during Redis outages with memory-based fallback
- Clear user messaging for rate limit exceeded with specific upgrade paths
- Comprehensive error logging for debugging and abuse pattern detection
- Automatic recovery mechanisms when Redis becomes available

**Performance Optimization**:
- Redis key optimization with efficient sliding window implementation
- Rate limit check caching with intelligent TTL management
- Database audit log optimization with batch inserts and async processing
- Memory usage optimization for high-concurrency rate limit checking

**Business Logic Validation**:
- Revenue protection through proper free tier rate limiting
- Professional tier value demonstration through higher limits and priority
- Abuse prevention with intelligent rate limiting and monitoring
- Customer experience protection through clear messaging and upgrade paths

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-01-11 | 1.0 | Initial story creation with basic requirements | User |
| 2025-01-11 | 2.0 | Comprehensive enhancement with full technical context, Redis integration, and production-ready rate limiting implementation | BMAD Agent |

## Dev Agent Record

*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results
*Results from QA Agent review of the completed story implementation*