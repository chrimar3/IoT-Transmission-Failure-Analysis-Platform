# Story 2.6: Supabase Resilience & Rate Limit Management

## Status
Ready (9/10)

## Story
**As a** system administrator,
**I want** comprehensive Supabase failure handling and rate limit management,
**so that** the CU-BEMS IoT platform remains functional and performant during database issues, connection limits, and service outages.

## Acceptance Criteria
1. **Connection Pooling & Retry Logic**: Database connections use pooling with automatic retry logic featuring exponential backoff (3 attempts max, 1s-4s-8s delays)
2. **Read-Only Mode**: System gracefully switches to read-only mode during database outages, serving cached data with clear user messaging
3. **Rate Limit Monitoring**: Real-time monitoring of Supabase rate limits with automated throttling at 80% threshold and proactive alerts
4. **Cached Data Serving**: Comprehensive caching strategy for analytics data during outages with TTL-based invalidation (6hr-24hr TTL)
5. **Automated Scaling Alerts**: Proactive alerts at 80% of service limits (storage, bandwidth, connections) with upgrade recommendations
6. **Graceful Query Degradation**: Progressive query simplification (full -> simplified -> cached) during performance issues with <1s fallback
7. **Dead Letter Queue**: Failed database operations queued for retry with manual reconciliation dashboard and 24hr max retention
8. **Connection Limit Handling**: Smart connection management to stay within Supabase free tier limits (target: <30 concurrent connections)
9. **Comprehensive Error Handling**: User-friendly error messages with fallback mechanisms and actionable recovery steps for all failure scenarios
10. **Performance Benchmarks**: <100ms simple queries, <1s complex queries, <30s failure recovery, >99.9% uptime during degraded mode

## Priority & Effort
**Priority**: P0 (Production Critical - Platform Stability)
**Effort**: 5 points
**Epic**: Epic 2 - User Authentication & Subscription Management

## Dev Notes

### Previous Story Insights
Building comprehensive resilience that extends across the entire Epic 2 infrastructure:

- **Story 2.5: Stripe API Failure Handling**: Establishes retry patterns and dead letter queue architecture that directly informs database resilience strategies. Exponential backoff patterns (1s-8s) and webhook failure recovery mechanisms provide proven templates for Supabase failure handling.
- **Story 2.4: Rate Limiting by Subscription Tier**: Provides Redis caching infrastructure and middleware patterns essential for database rate limiting. Coordination required for unified throttling across Stripe and Supabase APIs.
- **Story 2.2: Stripe Integration**: Subscription status caching during payment processing failures establishes caching patterns for database outage scenarios. User tier validation logic must remain functional during database degraded mode.
- **Story 2.1: NextAuth Authentication**: Session management and user authentication provide the foundation for secure connection pooling and permission-aware caching. User session state must be preserved during database failures.
- **Story 1.4: Core API Endpoints**: Establishes API error handling patterns and response formats that database resilience must extend. Rate limiting by subscription tier requires coordination with database connection limits.

**Critical Integration Points**:
- Unified caching strategy between Stripe payment status and Supabase subscription data
- Coordinated rate limiting across all external service dependencies  
- Session-aware connection pooling that respects user permissions during degraded mode
- Consistent error messaging and recovery patterns across all failure scenarios

### Data Models
[Source: architecture/7-database-schema-bangkok-dataset-optimized.md]

**Extended Core Tables with Resilience Tracking**:
- `sensor_readings` (3.2M rows): BIGSERIAL primary key, TIMESTAMPTZ indexing, optimized for query degradation
- `daily_aggregates` (materialized view): Pre-computed analytics data for cached serving during outages
- `subscriptions`: Enhanced with failure tracking and cached status for degraded mode operation

**New Resilience Management Tables**:

```sql
-- Database Connection Pool Monitoring
CREATE TABLE connection_pool_metrics (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    timestamp TIMESTAMPTZ DEFAULT NOW(),
    active_connections INTEGER NOT NULL,
    queued_requests INTEGER NOT NULL,
    pool_utilization DECIMAL(5,2) NOT NULL, -- Percentage of pool used
    query_duration_p95 INTEGER, -- 95th percentile query time in ms
    error_rate DECIMAL(5,4) NOT NULL DEFAULT 0, -- Error rate as decimal
    health_status VARCHAR(20) NOT NULL DEFAULT 'healthy' -- 'healthy' | 'degraded' | 'critical'
);

-- Dead Letter Queue for Failed Database Operations  
CREATE TABLE database_operation_failures (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    operation_type VARCHAR(50) NOT NULL, -- 'SELECT' | 'INSERT' | 'UPDATE' | 'DELETE'
    table_name VARCHAR(100) NOT NULL,
    user_id UUID REFERENCES auth.users(id),
    query_hash VARCHAR(64) NOT NULL, -- SHA-256 hash of query for deduplication
    failure_reason TEXT NOT NULL,
    retry_count INTEGER DEFAULT 0,
    max_retries INTEGER DEFAULT 3,
    next_retry_at TIMESTAMPTZ,
    original_payload JSONB, -- Original query parameters for retry
    resolved_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    
    CONSTRAINT max_retries_check CHECK (retry_count <= max_retries)
);

-- Service Health and Rate Limit Monitoring
CREATE TABLE service_health_metrics (
    service_name VARCHAR(50) PRIMARY KEY, -- 'supabase' | 'stripe' | 'redis' | 'auth'
    status VARCHAR(20) NOT NULL DEFAULT 'healthy', -- 'healthy' | 'degraded' | 'outage'
    last_check_at TIMESTAMPTZ DEFAULT NOW(),
    next_check_at TIMESTAMPTZ DEFAULT NOW() + INTERVAL '1 minute',
    current_rate_limit_usage INTEGER DEFAULT 0,
    rate_limit_threshold INTEGER DEFAULT 1000,
    connection_count INTEGER DEFAULT 0,
    connection_limit INTEGER DEFAULT 100,
    response_time_p95 INTEGER, -- Response time in milliseconds
    error_rate DECIMAL(5,4) DEFAULT 0,
    metadata JSONB, -- Service-specific metrics and alerts
    
    CONSTRAINT rate_limit_positive CHECK (rate_limit_threshold > 0),
    CONSTRAINT connection_limit_positive CHECK (connection_limit > 0)
);

-- Cached Analytics Data for Outage Serving
CREATE TABLE cached_analytics_data (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES auth.users(id),
    cache_key VARCHAR(255) NOT NULL, -- Computed cache key for quick lookup
    time_range VARCHAR(10) NOT NULL, -- '7d' | '30d' | '90d' | 'custom'
    query_params JSONB NOT NULL, -- Original query parameters
    result_data JSONB NOT NULL, -- Cached query results
    created_at TIMESTAMPTZ DEFAULT NOW(),
    expires_at TIMESTAMPTZ NOT NULL,
    hit_count INTEGER DEFAULT 0, -- Usage tracking for cache optimization
    last_accessed_at TIMESTAMPTZ DEFAULT NOW(),
    
    UNIQUE(user_id, cache_key),
    CONSTRAINT valid_time_range CHECK (time_range IN ('7d', '30d', '90d', 'custom'))
);

-- Database Performance Degradation Tracking
CREATE TABLE query_performance_log (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    query_signature VARCHAR(255) NOT NULL, -- Normalized query pattern
    execution_time_ms INTEGER NOT NULL,
    rows_affected INTEGER,
    degradation_applied BOOLEAN DEFAULT FALSE,
    fallback_used VARCHAR(50), -- 'simplified' | 'cached' | 'none'
    user_id UUID REFERENCES auth.users(id),
    table_names TEXT[], -- Array of table names accessed
    created_at TIMESTAMPTZ DEFAULT NOW(),
    
    CONSTRAINT positive_execution_time CHECK (execution_time_ms > 0)
);
```

**Enhanced Cache Data Models** [Source: architecture/8-api-architecture.md]:
```typescript
interface IEnhancedCachedAnalytics {
  id: string;
  userId: string;
  cacheKey: string;
  timeRange: '7d' | '30d' | '90d' | 'custom';
  queryParams: Record<string, any>;
  resultData: ISensorAnalytics;
  createdAt: Date;
  expiresAt: Date;
  hitCount: number;
  lastAccessedAt: Date;
}

interface IConnectionPoolHealth {
  timestamp: Date;
  activeConnections: number;
  queuedRequests: number;
  poolUtilization: number; // 0-100%
  queryDurationP95: number; // milliseconds
  errorRate: number; // 0-1
  healthStatus: 'healthy' | 'degraded' | 'critical';
}

interface IDatabaseFailureEvent {
  id: string;
  operationType: 'SELECT' | 'INSERT' | 'UPDATE' | 'DELETE';
  tableName: string;
  userId?: string;
  queryHash: string;
  failureReason: string;
  retryCount: number;
  maxRetries: number;
  nextRetryAt?: Date;
  originalPayload?: Record<string, any>;
  resolvedAt?: Date;
  createdAt: Date;
}

interface IServiceHealthStatus {
  serviceName: 'supabase' | 'stripe' | 'redis' | 'auth';
  status: 'healthy' | 'degraded' | 'outage';
  lastCheckAt: Date;
  nextCheckAt: Date;
  currentRateLimitUsage: number;
  rateLimitThreshold: number;
  connectionCount: number;
  connectionLimit: number;
  responseTimeP95: number;
  errorRate: number;
  metadata: Record<string, any>;
}
```

### API Specifications
[Source: architecture/coding-standards.md, architecture/8-api-architecture.md]

**Enhanced Supabase Client with Comprehensive Resilience**:
```typescript
// src/lib/database-resilience.ts
import { createClient, SupabaseClient } from '@supabase/supabase-js';
import { Database } from '@/types/database';

interface IResilienceConfig {
  maxConnections: number;
  connectionTimeout: number;
  queryTimeout: number;
  retryAttempts: number;
  retryBaseDelay: number; // milliseconds
  retryMaxDelay: number; // milliseconds
  circuitBreakerThreshold: number; // error rate 0-1
  cacheEnabled: boolean;
  cacheTTL: number; // seconds
}

export class ResilientSupabaseClient {
  private client: SupabaseClient<Database>;
  private config: IResilienceConfig;
  private connectionPool: Map<string, Connection> = new Map();
  private circuitBreaker: CircuitBreaker;
  private cache: CacheManager;

  constructor(config: IResilienceConfig) {
    this.client = createClient<Database>(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
      {
        global: {
          headers: {
            'x-client-version': '2.6-resilient',
            'x-connection-pool': 'enabled'
          }
        },
        db: { schema: 'public' },
        auth: { persistSession: true }
      }
    );
    this.config = config;
    this.circuitBreaker = new CircuitBreaker(config.circuitBreakerThreshold);
    this.cache = new CacheManager(config.cacheTTL);
  }

  async executeQuery<T>(
    query: () => Promise<T>,
    cacheKey?: string,
    degradationOptions?: QueryDegradationOptions
  ): Promise<T> {
    // Circuit breaker check
    if (!this.circuitBreaker.canExecute()) {
      return this.cache.get<T>(cacheKey!) || this.handleCircuitOpen(degradationOptions);
    }

    // Connection pool management
    const connection = await this.acquireConnection();
    
    try {
      // Retry logic with exponential backoff
      let lastError: Error;
      for (let attempt = 1; attempt <= this.config.retryAttempts; attempt++) {
        try {
          const startTime = Date.now();
          const result = await Promise.race([
            query(),
            new Promise((_, reject) => 
              setTimeout(() => reject(new Error('Query timeout')), this.config.queryTimeout)
            )
          ]) as T;
          
          const executionTime = Date.now() - startTime;
          await this.logQueryPerformance(query.toString(), executionTime, true);
          
          // Cache successful results
          if (cacheKey && this.config.cacheEnabled) {
            await this.cache.set(cacheKey, result, this.config.cacheTTL);
          }
          
          this.circuitBreaker.recordSuccess();
          return result;
        } catch (error) {
          lastError = error as Error;
          this.circuitBreaker.recordFailure();
          
          if (attempt < this.config.retryAttempts) {
            const delay = Math.min(
              this.config.retryBaseDelay * Math.pow(2, attempt - 1),
              this.config.retryMaxDelay
            );
            await this.sleep(delay);
          }
        }
      }
      
      // All retries failed - attempt degradation or fallback
      return await this.handleQueryFailure(lastError!, cacheKey, degradationOptions);
      
    } finally {
      this.releaseConnection(connection);
    }
  }

  private async handleQueryFailure<T>(
    error: Error,
    cacheKey?: string,
    degradationOptions?: QueryDegradationOptions
  ): Promise<T> {
    // Log failure for dead letter queue processing
    await this.logDatabaseFailure(error, degradationOptions?.querySignature);
    
    // Attempt cache fallback
    if (cacheKey) {
      const cachedResult = await this.cache.get<T>(cacheKey);
      if (cachedResult) {
        await this.logQueryPerformance(degradationOptions?.querySignature || 'unknown', 0, false, 'cached');
        return cachedResult;
      }
    }
    
    // Attempt query degradation
    if (degradationOptions?.simplifiedQuery) {
      try {
        const result = await degradationOptions.simplifiedQuery();
        await this.logQueryPerformance(degradationOptions.querySignature, 0, true, 'simplified');
        return result;
      } catch (degradationError) {
        // Simplified query also failed - log and throw original error
        await this.logDatabaseFailure(degradationError as Error, `${degradationOptions.querySignature}-simplified`);
      }
    }
    
    throw error;
  }
}

interface QueryDegradationOptions {
  querySignature: string;
  simplifiedQuery?: () => Promise<any>;
  fallbackData?: any;
}
```

**Comprehensive Resilience API Endpoints**:
- **GET /api/system/health** - Complete system health dashboard with real-time status
- **GET /api/system/database/metrics** - Detailed database performance and connection metrics  
- **GET /api/system/database/failures** - Dead letter queue status and retry statistics
- **POST /api/system/database/retry** - Manual retry of failed database operations (admin-only)
- **POST /api/system/maintenance** - Toggle read-only mode with user notification management
- **GET /api/system/cache/status** - Cache hit rates, expiration tracking, and performance metrics
- **DELETE /api/system/cache/invalidate** - Manual cache invalidation with selective key patterns
- **GET /api/admin/resilience/dashboard** - Administrative resilience monitoring dashboard
- **POST /api/admin/resilience/alert** - Manual alert testing and escalation management

**Advanced Monitoring and Rate Limiting Endpoints**:
```typescript
// GET /api/system/health - Comprehensive health check
interface ISystemHealthResponse {
  overall: 'healthy' | 'degraded' | 'critical';
  timestamp: string;
  services: {
    database: IServiceHealth;
    cache: IServiceHealth;
    auth: IServiceHealth;
    stripe: IServiceHealth;
  };
  metrics: {
    connectionPool: IConnectionPoolHealth;
    queryPerformance: IQueryPerformanceMetrics;
    errorRates: IErrorRateMetrics;
  };
  alerts: IActiveAlert[];
}

// GET /api/system/database/metrics - Detailed database metrics
interface IDatabaseMetricsResponse {
  connections: {
    active: number;
    queued: number;
    utilization: number;
    limit: number;
  };
  performance: {
    queryDurationP50: number;
    queryDurationP95: number;
    queryDurationP99: number;
    errorRate: number;
    throughput: number; // queries per second
  };
  rateLimits: {
    current: number;
    limit: number;
    resetAt: string;
    throttledRequests: number;
  };
  cache: {
    hitRate: number;
    missRate: number;
    size: number;
    evictionCount: number;
  };
}

// POST /api/system/database/retry - Manual retry operations  
interface IManualRetryRequest {
  operationIds: string[]; // Array of failed operation IDs
  priority: 'normal' | 'high' | 'critical';
  adminUserId: string;
  reason: string;
}

interface IManualRetryResponse {
  retriedOperations: string[];
  failedRetries: string[];
  estimatedCompletionTime: string;
  batchId: string;
}
```

**Circuit Breaker and Degradation Logic**:
```typescript
// Circuit breaker implementation for cascade failure prevention
export class CircuitBreaker {
  private failureCount = 0;
  private lastFailureTime = 0;
  private state: 'CLOSED' | 'OPEN' | 'HALF_OPEN' = 'CLOSED';
  
  constructor(
    private threshold: number,
    private timeout: number = 60000, // 1 minute
    private resetTimeout: number = 30000 // 30 seconds
  ) {}

  canExecute(): boolean {
    if (this.state === 'CLOSED') return true;
    
    if (this.state === 'OPEN') {
      if (Date.now() - this.lastFailureTime > this.resetTimeout) {
        this.state = 'HALF_OPEN';
        return true;
      }
      return false;
    }
    
    return true; // HALF_OPEN state allows single test request
  }

  recordSuccess(): void {
    if (this.state === 'HALF_OPEN') {
      this.state = 'CLOSED';
      this.failureCount = 0;
    }
  }

  recordFailure(): void {
    this.failureCount++;
    this.lastFailureTime = Date.now();
    
    if (this.failureCount >= this.threshold) {
      this.state = 'OPEN';
    }
  }
}
```

### Component Specifications
[Source: architecture/coding-standards.md]

**Comprehensive Database Health Monitoring Dashboard**:
```typescript
// src/components/features/resilience/DatabaseHealthDashboard.tsx
interface IDatabaseHealthDashboardProps {
  refreshInterval?: number; // Default 30 seconds
  alertThreshold?: number; // Default 80%
  showDetailedMetrics?: boolean;
  adminMode?: boolean; // Enable admin controls
  onCriticalAlert: (alert: ICriticalAlert) => void;
  onMaintenanceToggle: (readOnlyMode: boolean) => void;
}

export const DatabaseHealthDashboard: React.FC<IDatabaseHealthDashboardProps> = ({
  refreshInterval = 30000,
  alertThreshold = 0.8,
  showDetailedMetrics = false,
  adminMode = false,
  onCriticalAlert,
  onMaintenanceToggle
}) => {
  const [healthMetrics, setHealthMetrics] = useState<ISystemHealthResponse | null>(null);
  const [connectionMetrics, setConnectionMetrics] = useState<IConnectionPoolHealth | null>(null);
  const [failureQueue, setFailureQueue] = useState<IDatabaseFailureEvent[]>([]);
  const [maintenanceMode, setMaintenanceMode] = useState(false);

  // Real-time health monitoring with WebSocket connection
  useEffect(() => {
    const healthWs = new WebSocket(`${process.env.NEXT_PUBLIC_WS_URL}/health`);
    const interval = setInterval(fetchHealthMetrics, refreshInterval);
    
    return () => {
      healthWs.close();
      clearInterval(interval);
    };
  }, [refreshInterval]);

  return (
    <div className="database-health-dashboard">
      <ConnectionPoolMonitor 
        metrics={connectionMetrics}
        threshold={alertThreshold}
        onAlert={onCriticalAlert}
      />
      <QueryPerformanceChart 
        data={healthMetrics?.metrics.queryPerformance}
        showDegradation={showDetailedMetrics}
      />
      <FailureQueueStatus 
        failures={failureQueue}
        adminMode={adminMode}
        onRetryBatch={handleBatchRetry}
      />
      {adminMode && (
        <MaintenanceControls
          readOnlyMode={maintenanceMode}
          onToggle={onMaintenanceToggle}
        />
      )}
    </div>
  );
};
```

**Connection Pool Health Monitor Component**:
```typescript
// src/components/ui/ConnectionPoolMonitor.tsx
interface IConnectionPoolMonitorProps {
  metrics: IConnectionPoolHealth | null;
  threshold: number;
  showTrends?: boolean;
  onAlert: (alert: ICriticalAlert) => void;
}

export const ConnectionPoolMonitor: React.FC<IConnectionPoolMonitorProps> = ({
  metrics,
  threshold,
  showTrends = false,
  onAlert
}) => {
  const [alertHistory, setAlertHistory] = useState<ICriticalAlert[]>([]);
  const utilizationColor = useMemo(() => {
    if (!metrics) return 'gray';
    const utilization = metrics.poolUtilization / 100;
    if (utilization > 0.9) return 'red';
    if (utilization > threshold) return 'orange';
    return 'green';
  }, [metrics, threshold]);

  useEffect(() => {
    if (metrics && metrics.poolUtilization / 100 > threshold) {
      const alert: ICriticalAlert = {
        id: `pool-${Date.now()}`,
        type: 'CONNECTION_POOL_HIGH',
        severity: metrics.poolUtilization > 90 ? 'critical' : 'warning',
        message: `Connection pool utilization at ${metrics.poolUtilization.toFixed(1)}%`,
        timestamp: new Date(),
        metrics: {
          current: metrics.activeConnections,
          limit: 100, // Supabase free tier limit
          utilization: metrics.poolUtilization
        }
      };
      onAlert(alert);
      setAlertHistory(prev => [alert, ...prev.slice(0, 9)]);
    }
  }, [metrics, threshold, onAlert]);

  return (
    <Card className={`connection-pool-monitor border-${utilizationColor}-500`}>
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <DatabaseIcon className={`h-5 w-5 text-${utilizationColor}-500`} />
          Connection Pool Health
        </CardTitle>
      </CardHeader>
      <CardContent>
        {metrics ? (
          <>
            <div className="grid grid-cols-2 md:grid-cols-4 gap-4 mb-4">
              <MetricCard
                label="Active Connections"
                value={metrics.activeConnections}
                max={100}
                color={utilizationColor}
              />
              <MetricCard
                label="Queued Requests"
                value={metrics.queuedRequests}
                alert={metrics.queuedRequests > 10}
              />
              <MetricCard
                label="Pool Utilization"
                value={`${metrics.poolUtilization.toFixed(1)}%`}
                color={utilizationColor}
              />
              <MetricCard
                label="Query P95"
                value={`${metrics.queryDurationP95}ms`}
                alert={metrics.queryDurationP95 > 1000}
              />
            </div>
            
            {showTrends && (
              <UtilizationTrendChart data={metrics} />
            )}
            
            {alertHistory.length > 0 && (
              <AlertHistoryList alerts={alertHistory.slice(0, 3)} />
            )}
          </>
        ) : (
          <div className="flex items-center justify-center p-8">
            <Spinner /> Loading connection metrics...
          </div>
        )}
      </CardContent>
    </Card>
  );
};
```

**Resilient Error Boundary with Fallback Strategies**:
```typescript
// src/components/ui/DatabaseErrorBoundary.tsx
interface IDatabaseErrorBoundaryProps {
  children: React.ReactNode;
  fallbackComponent?: React.ComponentType<{error: Error; reset: () => void}>;
  cacheProvider?: CacheManager;
  retryEnabled?: boolean;
  maxRetries?: number;
  onError?: (error: Error, errorInfo: ErrorInfo) => void;
}

interface IDatabaseErrorBoundaryState {
  hasError: boolean;
  error: Error | null;
  retryCount: number;
  fallbackMode: 'none' | 'cached' | 'simplified' | 'offline';
  cachedData: any;
}

export class DatabaseErrorBoundary extends React.Component<
  IDatabaseErrorBoundaryProps, 
  IDatabaseErrorBoundaryState
> {
  constructor(props: IDatabaseErrorBoundaryProps) {
    super(props);
    this.state = {
      hasError: false,
      error: null,
      retryCount: 0,
      fallbackMode: 'none',
      cachedData: null
    };
  }

  static getDerivedStateFromError(error: Error): Partial<IDatabaseErrorBoundaryState> {
    return {
      hasError: true,
      error,
      fallbackMode: 'cached' // Start with cached data attempt
    };
  }

  async componentDidCatch(error: Error, errorInfo: ErrorInfo) {
    // Log error to monitoring service
    console.error('Database error boundary triggered:', error, errorInfo);
    this.props.onError?.(error, errorInfo);

    // Attempt to load cached data
    if (this.props.cacheProvider) {
      try {
        const cachedData = await this.props.cacheProvider.getFallbackData();
        if (cachedData) {
          this.setState({ cachedData, fallbackMode: 'cached' });
          return;
        }
      } catch (cacheError) {
        console.error('Cache fallback failed:', cacheError);
      }
    }

    // Set to simplified mode if no cache available
    this.setState({ fallbackMode: 'simplified' });
  }

  handleRetry = async () => {
    if (this.state.retryCount >= (this.props.maxRetries || 3)) {
      this.setState({ fallbackMode: 'offline' });
      return;
    }

    this.setState(prevState => ({
      hasError: false,
      error: null,
      retryCount: prevState.retryCount + 1,
      fallbackMode: 'none'
    }));
  };

  render() {
    if (this.state.hasError) {
      const FallbackComponent = this.props.fallbackComponent || DefaultDatabaseErrorFallback;
      
      return (
        <FallbackComponent 
          error={this.state.error!}
          fallbackMode={this.state.fallbackMode}
          cachedData={this.state.cachedData}
          onRetry={this.props.retryEnabled ? this.handleRetry : undefined}
          retryCount={this.state.retryCount}
          maxRetries={this.props.maxRetries || 3}
        />
      );
    }

    return this.props.children;
  }
}

// Default fallback component with user-friendly messaging
const DefaultDatabaseErrorFallback: React.FC<{
  error: Error;
  fallbackMode: string;
  cachedData: any;
  onRetry?: () => void;
  retryCount: number;
  maxRetries: number;
}> = ({ error, fallbackMode, cachedData, onRetry, retryCount, maxRetries }) => {
  return (
    <div className="database-error-fallback p-6 bg-yellow-50 border-l-4 border-yellow-400">
      <div className="flex items-start">
        <AlertTriangleIcon className="h-6 w-6 text-yellow-600 mr-3 mt-1" />
        <div className="flex-1">
          <h3 className="text-lg font-medium text-yellow-800">
            {fallbackMode === 'cached' ? 'Showing Cached Data' : 
             fallbackMode === 'simplified' ? 'Limited Functionality Mode' : 
             'Service Temporarily Unavailable'}
          </h3>
          <div className="mt-2 text-sm text-yellow-700">
            {fallbackMode === 'cached' && (
              <p>We're experiencing connectivity issues. Showing your last saved data while we resolve the problem.</p>
            )}
            {fallbackMode === 'simplified' && (
              <p>Some features are temporarily limited. Basic functionality is still available.</p>
            )}
            {fallbackMode === 'offline' && (
              <p>Unable to connect to our services. Please check your internet connection and try again.</p>
            )}
          </div>
          
          {onRetry && retryCount < maxRetries && (
            <div className="mt-4">
              <button
                onClick={onRetry}
                className="bg-yellow-600 hover:bg-yellow-700 text-white px-4 py-2 rounded text-sm font-medium"
              >
                Retry Connection ({retryCount}/{maxRetries})
              </button>
            </div>
          )}
          
          <details className="mt-4">
            <summary className="cursor-pointer text-yellow-600 hover:text-yellow-800 text-sm">
              Technical Details
            </summary>
            <pre className="mt-2 text-xs bg-yellow-100 p-2 rounded overflow-auto">
              {error.message}
            </pre>
          </details>
        </div>
      </div>
    </div>
  );
};
```

**Cache Status and Management Component**:
```typescript
// src/components/features/resilience/CacheStatusManager.tsx
interface ICacheStatusManagerProps {
  adminMode?: boolean;
  onCacheInvalidation?: (pattern: string) => void;
  onCacheWarmup?: (keys: string[]) => void;
}

export const CacheStatusManager: React.FC<ICacheStatusManagerProps> = ({
  adminMode = false,
  onCacheInvalidation,
  onCacheWarmup
}) => {
  const [cacheMetrics, setCacheMetrics] = useState<ICacheMetrics | null>(null);
  const [invalidationPattern, setInvalidationPattern] = useState('');
  
  return (
    <Card className="cache-status-manager">
      <CardHeader>
        <CardTitle className="flex items-center justify-between">
          <span>Cache Performance</span>
          {adminMode && (
            <Button
              variant="outline"
              size="sm"
              onClick={() => onCacheInvalidation?.('*')}
            >
              Clear All Cache
            </Button>
          )}
        </CardTitle>
      </CardHeader>
      <CardContent>
        <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
          <MetricCard
            label="Hit Rate"
            value={`${((cacheMetrics?.hitRate || 0) * 100).toFixed(1)}%`}
            color={cacheMetrics?.hitRate > 0.9 ? 'green' : cacheMetrics?.hitRate > 0.7 ? 'orange' : 'red'}
          />
          <MetricCard
            label="Cache Size"
            value={formatBytes(cacheMetrics?.size || 0)}
          />
          <MetricCard
            label="Evictions/Hour"
            value={cacheMetrics?.evictionRate || 0}
            alert={(cacheMetrics?.evictionRate || 0) > 100}
          />
          <MetricCard
            label="TTL Utilization"
            value={`${((cacheMetrics?.ttlUtilization || 0) * 100).toFixed(1)}%`}
          />
        </div>
        
        {adminMode && (
          <div className="mt-6 p-4 bg-gray-50 rounded">
            <h4 className="font-medium mb-2">Cache Management</h4>
            <div className="flex gap-2">
              <input
                type="text"
                placeholder="Cache key pattern (e.g., 'analytics:*')"
                value={invalidationPattern}
                onChange={(e) => setInvalidationPattern(e.target.value)}
                className="flex-1 px-3 py-2 border rounded"
              />
              <Button
                onClick={() => onCacheInvalidation?.(invalidationPattern)}
                disabled={!invalidationPattern}
              >
                Invalidate Pattern
              </Button>
            </div>
          </div>
        )}
      </CardContent>
    </Card>
  );
};
```

### File Locations
[Source: architecture/source-tree.md]

**Core Resilience Implementation**:
- `/src/lib/database-resilience.ts` - ResilientSupabaseClient with retry logic, circuit breaker, and connection pooling
- `/src/lib/connection-pool.ts` - Connection pool management and health monitoring
- `/src/lib/circuit-breaker.ts` - Circuit breaker implementation for cascade failure prevention
- `/src/lib/cache-manager.ts` - Cache management with Redis/memory fallback and TTL handling
- `/src/lib/query-degradation.ts` - Query simplification and fallback logic
- `/src/lib/dead-letter-queue.ts` - Failed operation queuing and retry processing

**Monitoring and Health Components**:
- `/src/components/features/resilience/DatabaseHealthDashboard.tsx` - Main health monitoring dashboard
- `/src/components/ui/ConnectionPoolMonitor.tsx` - Real-time connection pool visualization
- `/src/components/ui/DatabaseErrorBoundary.tsx` - Error boundary with intelligent fallbacks
- `/src/components/features/resilience/CacheStatusManager.tsx` - Cache performance monitoring
- `/src/components/ui/FailureQueueStatus.tsx` - Dead letter queue management interface
- `/src/components/ui/MaintenanceControls.tsx` - Admin maintenance mode controls

**API Endpoints and Middleware**:
- `/src/app/api/system/health/route.ts` - Comprehensive system health endpoint
- `/src/app/api/system/database/metrics/route.ts` - Detailed database performance metrics
- `/src/app/api/system/database/failures/route.ts` - Dead letter queue status and management
- `/src/app/api/system/database/retry/route.ts` - Manual retry operations for administrators
- `/src/app/api/system/maintenance/route.ts` - Read-only mode toggle and status
- `/src/app/api/system/cache/status/route.ts` - Cache metrics and performance data
- `/src/app/api/system/cache/invalidate/route.ts` - Cache invalidation controls
- `/src/app/api/admin/resilience/dashboard/route.ts` - Admin-only resilience dashboard data

**Custom Hooks and Utilities**:
- `/src/hooks/useDatabaseHealth.ts` - Real-time database health monitoring hook
- `/src/hooks/useConnectionPool.ts` - Connection pool status and metrics
- `/src/hooks/useResilientQuery.ts` - Hook for queries with automatic retry and caching
- `/src/hooks/useFailureQueue.ts` - Dead letter queue monitoring and management
- `/src/hooks/useMaintenanceMode.ts` - Maintenance mode state and controls

**Enhanced Middleware**:
- `/src/middleware.ts` - Enhanced with database health checks and automatic failover
- `/src/lib/middleware/resilience-middleware.ts` - Database resilience-specific middleware
- `/src/lib/middleware/rate-limit-middleware.ts` - Coordinated rate limiting with database pools

**Configuration and Environment**:
- `/src/lib/config/resilience-config.ts` - Resilience system configuration
- `/src/lib/config/supabase-config.ts` - Enhanced Supabase client configuration
- `/.env.example` - Updated with resilience-specific environment variables
- `/scripts/database-health-monitor.js` - Background health monitoring script
- `/scripts/dead-letter-processor.js` - Automated retry processing script

**Database Schema Extensions**:
- `/scripts/database/resilience-tables.sql` - SQL for resilience tracking tables
- `/scripts/database/indexes.sql` - Performance indexes for monitoring queries
- `/scripts/database/triggers.sql` - Automated metric collection triggers

**Type Definitions**:
- `/src/types/resilience.ts` - TypeScript interfaces for resilience system
- `/src/types/monitoring.ts` - Health monitoring and metrics types
- `/src/types/cache.ts` - Cache management and performance types

### Testing Requirements
[Source: architecture/5-testing-framework-setup-installation.md]

**Comprehensive Testing Coverage Target: 90%** (Exceeding 85% minimum requirement)

**Unit Testing (Target: 95% Coverage)**:
```typescript
// __tests__/lib/database-resilience.test.ts
describe('ResilientSupabaseClient', () => {
  describe('Connection Management', () => {
    it('should create connection pool within configured limits', async () => {
      const client = new ResilientSupabaseClient({ maxConnections: 20 });
      expect(client.getConnectionCount()).toBeLessThanOrEqual(20);
    });

    it('should queue requests when connection pool is full', async () => {
      const client = new ResilientSupabaseClient({ maxConnections: 5 });
      // Simulate 10 concurrent requests
      const promises = Array(10).fill(null).map(() => client.executeQuery(() => mockQuery()));
      const startTime = Date.now();
      await Promise.all(promises);
      // Verify queuing behavior and no dropped requests
      expect(promises).toHaveLength(10);
    });

    it('should release connections after query completion', async () => {
      const client = new ResilientSupabaseClient({ maxConnections: 10 });
      const initialCount = client.getActiveConnectionCount();
      await client.executeQuery(() => mockQuery());
      expect(client.getActiveConnectionCount()).toEqual(initialCount);
    });
  });

  describe('Retry Logic with Exponential Backoff', () => {
    it('should retry failed queries with exponential backoff (1s, 2s, 4s)', async () => {
      const mockQuery = jest.fn()
        .mockRejectedValueOnce(new Error('Connection failed'))
        .mockRejectedValueOnce(new Error('Connection failed'))
        .mockResolvedValueOnce({ data: 'success' });

      const startTime = Date.now();
      const result = await client.executeQuery(mockQuery);
      const totalTime = Date.now() - startTime;

      expect(mockQuery).toHaveBeenCalledTimes(3);
      expect(totalTime).toBeGreaterThanOrEqual(7000); // 1s + 2s + 4s delays
      expect(result.data).toBe('success');
    });

    it('should respect maximum retry attempts', async () => {
      const mockQuery = jest.fn().mockRejectedValue(new Error('Persistent failure'));
      
      await expect(client.executeQuery(mockQuery)).rejects.toThrow('Persistent failure');
      expect(mockQuery).toHaveBeenCalledTimes(3); // Initial + 2 retries
    });

    it('should add jitter to prevent thundering herd', async () => {
      const delays: number[] = [];
      const mockDelay = jest.fn((ms) => { delays.push(ms); return Promise.resolve(); });
      
      // Test multiple failed queries in parallel
      await Promise.allSettled(
        Array(5).fill(null).map(() => client.executeQueryWithDelay(mockQuery, mockDelay))
      );
      
      // Verify delays are not identical (jitter applied)
      expect(new Set(delays).size).toBeGreaterThan(1);
    });
  });

  describe('Circuit Breaker Pattern', () => {
    it('should open circuit after threshold failures', async () => {
      const client = new ResilientSupabaseClient({ circuitBreakerThreshold: 5 });
      const mockQuery = jest.fn().mockRejectedValue(new Error('Service down'));
      
      // Trigger 5 failures to open circuit
      for (let i = 0; i < 5; i++) {
        try { await client.executeQuery(mockQuery); } catch {}
      }
      
      expect(client.circuitBreaker.getState()).toBe('OPEN');
      
      // Next request should fail fast without calling query
      const fastFailStart = Date.now();
      await expect(client.executeQuery(mockQuery)).rejects.toThrow();
      const fastFailTime = Date.now() - fastFailStart;
      
      expect(fastFailTime).toBeLessThan(100); // Should fail in < 100ms
      expect(mockQuery).toHaveBeenCalledTimes(5); // No additional calls when circuit open
    });

    it('should transition to half-open after reset timeout', async () => {
      const client = new ResilientSupabaseClient({ 
        circuitBreakerThreshold: 3,
        resetTimeout: 1000 
      });
      
      // Open circuit
      await triggerCircuitOpen(client);
      expect(client.circuitBreaker.getState()).toBe('OPEN');
      
      // Wait for reset timeout
      await new Promise(resolve => setTimeout(resolve, 1100));
      
      // Next request should attempt to execute (half-open state)
      const mockQuery = jest.fn().mockResolvedValue({ data: 'recovered' });
      const result = await client.executeQuery(mockQuery);
      
      expect(client.circuitBreaker.getState()).toBe('CLOSED');
      expect(result.data).toBe('recovered');
    });
  });
});

// __tests__/lib/cache-manager.test.ts  
describe('CacheManager', () => {
  describe('Cache Operations', () => {
    it('should cache successful query results with TTL', async () => {
      const cache = new CacheManager();
      const testData = { analytics: 'data' };
      
      await cache.set('analytics:user123:7d', testData, 3600);
      const cached = await cache.get('analytics:user123:7d');
      
      expect(cached).toEqual(testData);
    });

    it('should expire cache entries after TTL', async () => {
      const cache = new CacheManager();
      const testData = { analytics: 'data' };
      
      await cache.set('test:key', testData, 1); // 1 second TTL
      await new Promise(resolve => setTimeout(resolve, 1100));
      
      const expired = await cache.get('test:key');
      expect(expired).toBeNull();
    });

    it('should fallback to memory cache when Redis fails', async () => {
      const cache = new CacheManager({ redisEnabled: true });
      // Mock Redis failure
      cache.redis = mockFailingRedis();
      
      await cache.set('failover:test', { data: 'memory' });
      const result = await cache.get('failover:test');
      
      expect(result.data).toBe('memory');
      expect(cache.getMetrics().fallbackCount).toBe(1);
    });

    it('should implement cache warming for critical data', async () => {
      const cache = new CacheManager();
      const warmupKeys = ['analytics:summary', 'dashboard:metrics'];
      
      await cache.warmup(warmupKeys, mockDataProvider);
      
      for (const key of warmupKeys) {
        const cached = await cache.get(key);
        expect(cached).toBeDefined();
      }
    });
  });

  describe('Cache Invalidation', () => {
    it('should invalidate cache by pattern', async () => {
      const cache = new CacheManager();
      
      await cache.set('analytics:user1:7d', { data: '1' });
      await cache.set('analytics:user2:7d', { data: '2' });
      await cache.set('dashboard:user1', { data: '3' });
      
      await cache.invalidatePattern('analytics:*');
      
      expect(await cache.get('analytics:user1:7d')).toBeNull();
      expect(await cache.get('analytics:user2:7d')).toBeNull();
      expect(await cache.get('dashboard:user1')).toBeDefined();
    });
  });
});

// __tests__/lib/dead-letter-queue.test.ts
describe('DeadLetterQueue', () => {
  it('should queue failed operations with metadata', async () => {
    const dlq = new DeadLetterQueue();
    const failedOperation = {
      operationType: 'SELECT',
      tableName: 'sensor_readings',
      query: 'SELECT * FROM sensor_readings WHERE user_id = $1',
      parameters: ['user123'],
      error: new Error('Connection timeout')
    };
    
    await dlq.enqueue(failedOperation);
    const queueSize = await dlq.getSize();
    
    expect(queueSize).toBe(1);
  });

  it('should retry operations with progressive backoff', async () => {
    const dlq = new DeadLetterQueue();
    const retryTimes: number[] = [];
    
    const mockOperation = {
      execute: jest.fn()
        .mockRejectedValueOnce(new Error('Still failing'))
        .mockResolvedValueOnce({ success: true }),
      getNextRetryTime: () => retryTimes
    };
    
    await dlq.processRetries();
    
    // Verify progressive backoff: 5min, 15min, 1hr, 6hr
    expect(retryTimes[0]).toBeCloseTo(5 * 60 * 1000, -3); // ~5 minutes
    expect(retryTimes[1]).toBeCloseTo(15 * 60 * 1000, -3); // ~15 minutes
  });

  it('should move operations to permanent failure after max retries', async () => {
    const dlq = new DeadLetterQueue({ maxRetries: 3 });
    const failedOp = createMockFailedOperation();
    
    await dlq.enqueue(failedOp);
    
    // Simulate 3 failed retries
    for (let i = 0; i < 3; i++) {
      await dlq.processRetries();
    }
    
    const permanentFailures = await dlq.getPermanentFailures();
    expect(permanentFailures).toHaveLength(1);
    expect(permanentFailures[0].retryCount).toBe(3);
  });
});
```

**Integration Testing with Database Simulation**:
```typescript
// __tests__/integration/database-outage.test.ts
describe('Database Outage Scenarios', () => {
  it('should maintain read functionality during database outage', async () => {
    // Mock complete database failure
    mockSupabaseClient.mockImplementation(() => {
      throw new Error('ECONNREFUSED: Connection refused');
    });
    
    const analyticsService = new AnalyticsService();
    
    // Should serve cached data without errors
    const result = await analyticsService.getDashboardData('user123');
    
    expect(result).toBeDefined();
    expect(result.source).toBe('cache');
    expect(result.data).toMatchObject({
      sensors: expect.any(Array),
      summary: expect.any(Object)
    });
  });

  it('should gracefully degrade complex queries to simple ones', async () => {
    // Mock slow database responses (>1s timeout)
    mockSupabaseClient.mockImplementation(async () => {
      await new Promise(resolve => setTimeout(resolve, 2000));
      throw new Error('Query timeout');
    });
    
    const analyticsService = new AnalyticsService();
    
    // Complex query should fallback to simplified version
    const result = await analyticsService.getDetailedAnalytics('user123', {
      timeRange: '30d',
      aggregation: 'hourly',
      includeBreakdown: true
    });
    
    expect(result).toBeDefined();
    expect(result.degraded).toBe(true);
    expect(result.simplificationLevel).toBe('basic');
  });

  it('should recover automatically when database comes back online', async () => {
    const client = new ResilientSupabaseClient();
    
    // Start with database failure
    mockSupabaseClient.mockRejectedValue(new Error('Database down'));
    
    // Verify circuit opens
    await expect(client.executeQuery(mockQuery)).rejects.toThrow();
    expect(client.circuitBreaker.getState()).toBe('OPEN');
    
    // Database recovers
    mockSupabaseClient.mockResolvedValue({ data: 'back online' });
    
    // Wait for circuit to attempt recovery
    await new Promise(resolve => setTimeout(resolve, 31000)); // Reset timeout + buffer
    
    // Should execute successfully
    const result = await client.executeQuery(mockQuery);
    expect(result.data).toBe('back online');
    expect(client.circuitBreaker.getState()).toBe('CLOSED');
  });
});
```

**Load and Stress Testing**:
```typescript
// __tests__/load/connection-limits.test.ts
describe('Connection Pool Stress Testing', () => {
  it('should handle 100 concurrent requests without dropping any', async () => {
    const client = new ResilientSupabaseClient({ maxConnections: 30 });
    const concurrentRequests = 100;
    const results = [];
    
    const promises = Array(concurrentRequests).fill(null).map(async (_, index) => {
      const result = await client.executeQuery(() => 
        mockQuery(`SELECT ${index} as request_id`)
      );
      results.push(result);
    });
    
    await Promise.all(promises);
    
    expect(results).toHaveLength(concurrentRequests);
    expect(results.filter(r => r.error)).toHaveLength(0);
    expect(client.getMaxConnectionsReached()).toBe(true);
  });

  it('should maintain performance under sustained load', async () => {
    const client = new ResilientSupabaseClient();
    const testDuration = 60000; // 1 minute
    const requestInterval = 100; // Every 100ms
    const performanceMetrics = [];
    
    const startTime = Date.now();
    
    while (Date.now() - startTime < testDuration) {
      const requestStart = Date.now();
      await client.executeQuery(mockQuery);
      const requestTime = Date.now() - requestStart;
      
      performanceMetrics.push(requestTime);
      await new Promise(resolve => setTimeout(resolve, requestInterval));
    }
    
    const avgResponseTime = performanceMetrics.reduce((a, b) => a + b, 0) / performanceMetrics.length;
    const p95ResponseTime = calculatePercentile(performanceMetrics, 95);
    
    expect(avgResponseTime).toBeLessThan(500); // <500ms average
    expect(p95ResponseTime).toBeLessThan(1000); // <1s P95
  });
});
```

**End-to-End Testing with Real User Flows**:
```typescript
// __tests__/e2e/user-experience-during-failures.test.ts
describe('User Experience During Database Issues', () => {
  it('should show appropriate messages during maintenance mode', async () => {
    // Enable maintenance mode
    await request(app)
      .post('/api/system/maintenance')
      .send({ readOnlyMode: true, reason: 'Scheduled maintenance' })
      .expect(200);
    
    // User attempts to access dashboard
    const response = await request(app)
      .get('/dashboard')
      .set('Cookie', validUserSession)
      .expect(200);
    
    expect(response.text).toContain('System is temporarily in read-only mode');
    expect(response.text).toContain('Scheduled maintenance');
    
    // Analytics should still work (cached data)
    const analyticsResponse = await request(app)
      .get('/api/analytics/dashboard')
      .set('Cookie', validUserSession)
      .expect(200);
    
    expect(analyticsResponse.body.data).toBeDefined();
    expect(analyticsResponse.body.source).toBe('cache');
  });

  it('should handle payment processing during database issues', async () => {
    // Mock database failure during subscription creation
    mockSupabaseClient.mockRejectedValue(new Error('Database unavailable'));
    
    const subscriptionRequest = {
      tier: 'premium',
      priceId: 'price_premium_monthly'
    };
    
    const response = await request(app)
      .post('/api/subscription/create')
      .send(subscriptionRequest)
      .set('Cookie', validUserSession)
      .expect(202); // Accepted but not immediately processed
    
    expect(response.body.status).toBe('queued');
    expect(response.body.message).toContain('processed once service is restored');
    
    // Verify operation is queued in dead letter queue
    const dlqStatus = await request(app)
      .get('/api/system/database/failures')
      .set('Cookie', adminSession)
      .expect(200);
    
    expect(dlqStatus.body.pendingOperations).toBeGreaterThan(0);
  });
});
```

**Chaos Engineering and Disaster Recovery Tests**:
```typescript
// __tests__/chaos/disaster-scenarios.test.ts
describe('Chaos Engineering - Disaster Scenarios', () => {
  it('should survive complete service dependency failures', async () => {
    // Simulate multiple service failures simultaneously
    mockSupabaseClient.mockRejectedValue(new Error('Database cluster down'));
    mockRedisClient.mockRejectedValue(new Error('Redis cluster down'));
    mockStripeClient.mockRejectedValue(new Error('Stripe API down'));
    
    const app = createTestApp();
    
    // Critical user flows should still work with degraded functionality
    const dashboardResponse = await request(app)
      .get('/dashboard')
      .set('Cookie', validUserSession)
      .expect(200);
    
    expect(dashboardResponse.text).toContain('Limited functionality mode');
    
    // Health check should report degraded but not failed
    const healthResponse = await request(app)
      .get('/api/system/health')
      .expect(200);
    
    expect(healthResponse.body.overall).toBe('degraded');
    expect(healthResponse.body.services.database.status).toBe('critical');
  });

  it('should handle cascading failures gracefully', async () => {
    const client = new ResilientSupabaseClient();
    
    // Start with high load
    const highLoadPromises = Array(50).fill(null).map(() => client.executeQuery(mockQuery));
    
    // Introduce database latency during high load
    mockSupabaseClient.mockImplementation(async () => {
      await new Promise(resolve => setTimeout(resolve, 2000)); // 2s delay
      throw new Error('Query timeout');
    });
    
    // Should not cause system crash
    const results = await Promise.allSettled(highLoadPromises);
    const failures = results.filter(r => r.status === 'rejected');
    
    // Some requests may fail, but system should remain stable
    expect(failures.length / results.length).toBeLessThan(0.5); // <50% failure rate
    expect(client.circuitBreaker.getState()).toBe('OPEN'); // Circuit should open to protect
  });
});
```

**Performance Benchmark Validation**:
```typescript
// __tests__/performance/benchmarks.test.ts
describe('Performance Benchmarks Validation', () => {
  it('should meet simple query performance target (<100ms)', async () => {
    const client = new ResilientSupabaseClient();
    const iterations = 100;
    const responseTimes = [];
    
    for (let i = 0; i < iterations; i++) {
      const start = Date.now();
      await client.executeQuery(() => mockSimpleQuery());
      const duration = Date.now() - start;
      responseTimes.push(duration);
    }
    
    const averageTime = responseTimes.reduce((a, b) => a + b, 0) / iterations;
    const p95Time = calculatePercentile(responseTimes, 95);
    
    expect(averageTime).toBeLessThan(100);
    expect(p95Time).toBeLessThan(150); // Allow some variance for P95
  });

  it('should meet complex query performance target (<1s)', async () => {
    const client = new ResilientSupabaseClient();
    const complexQueryTimes = [];
    
    for (let i = 0; i < 20; i++) {
      const start = Date.now();
      await client.executeQuery(() => mockComplexAnalyticsQuery());
      const duration = Date.now() - start;
      complexQueryTimes.push(duration);
    }
    
    const averageTime = complexQueryTimes.reduce((a, b) => a + b, 0) / 20;
    expect(averageTime).toBeLessThan(1000);
  });

  it('should achieve >99.9% uptime during degraded mode', async () => {
    const testDuration = 300000; // 5 minutes
    const requestInterval = 1000; // Every second
    const startTime = Date.now();
    let successfulRequests = 0;
    let totalRequests = 0;
    
    // Simulate intermittent database issues
    mockSupabaseClient.mockImplementation(() => {
      if (Math.random() < 0.1) { // 10% failure rate
        throw new Error('Intermittent database issue');
      }
      return Promise.resolve({ data: 'success' });
    });
    
    while (Date.now() - startTime < testDuration) {
      try {
        await client.executeQuery(mockQuery);
        successfulRequests++;
      } catch (error) {
        // Failures are expected
      }
      totalRequests++;
      await new Promise(resolve => setTimeout(resolve, requestInterval));
    }
    
    const uptime = successfulRequests / totalRequests;
    expect(uptime).toBeGreaterThan(0.999); // >99.9% success rate
  });
});
```

### Technical Constraints
[Source: architecture/8-api-architecture.md, architecture/2-ultra-lean-technology-stack.md]

**Supabase Free Tier Limits (Critical Constraints)**:
- **Storage**: 500MB total database storage with 134 sensors × 3.2M readings optimization
- **Bandwidth**: 2GB/month data transfer requiring aggressive caching and query optimization
- **Concurrent Connections**: 100 maximum connections requiring intelligent pooling (target: <30 active)
- **API Requests**: 50,000/month requiring request batching and circuit breaker protection
- **Real-time Connections**: 2 concurrent real-time subscriptions limiting live monitoring features
- **Database Size**: 1GB total including all tables, indexes, and materialized views

**Bangkok Dataset Specific Constraints**:
- **Sensor Data Volume**: 3.2M sensor readings requiring partitioning and archival strategies
- **Query Complexity**: 134 sensors × 7 floors = 938 sensor combinations requiring optimized aggregation
- **Time Range Queries**: 2+ years of historical data requiring materialized view caching
- **Real-time Processing**: Live sensor data ingestion must not impact user queries

**Connection Pool Architecture Constraints**:
- **Max Active Connections**: 30 (well under Supabase 100 limit with 70 connection safety buffer)
- **Connection Acquisition Timeout**: 10 seconds maximum wait time for connection
- **Idle Connection Timeout**: 30 seconds before connection is released to pool
- **Query Execution Timeout**: 30 seconds for complex queries, 5 seconds for simple queries
- **Circuit Breaker Threshold**: 5 consecutive failures triggers open circuit for 60 seconds

**Performance Benchmarks (SLA Requirements)**:
- **Simple Queries** (<50 rows): <100ms P95 response time including caching
- **Complex Analytics** (>10K rows): <1000ms P95 response time with query degradation
- **Cache Hit Ratio**: >95% for dashboard queries during normal operation
- **Error Rate**: <0.1% for database operations during healthy state
- **Uptime During Degraded Mode**: >99.9% availability serving cached data
- **Failure Recovery Time**: <30 seconds from database restoration to full functionality

**Infrastructure Budget Constraints**:
- **Total Monthly Cost**: $0-20 maximum including all services and monitoring
- **Caching Solution**: Vercel KV (1GB storage, 100K operations) or memory-only fallback
- **Monitoring**: Sentry free tier (5K error events/month) with custom health checks
- **Alerting**: Email notifications only, no SMS/Slack premium integrations
- **Backup Strategy**: Supabase automated backups only, no external backup services

**Integration Coordination Requirements**:
- **Story 2.4 Redis Coordination**: Shared cache keys and invalidation patterns
- **Story 2.5 Stripe Coordination**: Unified retry patterns and dead letter queue processing
- **Story 2.1 Auth Coordination**: Session-aware connection pooling with user permission caching
- **Story 1.4 API Coordination**: Consistent error response formats and rate limiting headers

### Security Considerations
[Source: architecture/coding-standards.md, architecture/9-security-implementation.md]

**Database Access Control and RLS Enforcement**:
- **Row Level Security (RLS)**: All RLS policies must remain active during degraded mode operation
- **Service Role Key Protection**: Service role key only used for internal health checks, never exposed to client-side code
- **Connection Pool Security**: User session isolation maintained across shared connections using connection-level security context
- **Query Parameter Sanitization**: All cached queries must use parameterized statements preventing SQL injection
- **Permission-Aware Caching**: Cache keys include user permission hash to prevent cross-user data exposure

**Authentication and Session Management Security**:
- **Session-Aware Pooling**: Connection pooling respects user authentication state and subscription tier permissions
- **Token Validation**: JWT tokens validated on every resilience operation to prevent unauthorized cache access
- **Admin Operation Security**: Dead letter queue management and manual retry operations require admin role verification
- **API Key Rotation**: Health monitoring endpoints secured with rotating API keys, no hardcoded credentials
- **Audit Trail**: All manual interventions and admin operations logged with user attribution and timestamps

**Cache Security and Data Protection**:
- **Cache Encryption**: All cached data encrypted at rest using AES-256 encryption
- **TTL Security**: Cache expiration enforced to prevent stale permission data serving outdated access levels
- **Cache Invalidation Security**: Pattern-based cache invalidation restricted to admin users with rate limiting
- **User Data Isolation**: Cache keys namespaced by user ID and subscription tier to prevent data leakage
- **Memory Protection**: In-memory fallback cache cleared on user logout to prevent memory-based data exposure

**Network Security and Rate Limiting**:
- **Connection Pool Rate Limiting**: Per-user connection limits prevent individual users from exhausting pool resources
- **API Endpoint Protection**: Health and metrics endpoints protected with API authentication and IP allowlisting
- **Request Signing**: Critical admin operations (manual retry, maintenance mode) require request signing with admin private key
- **Circuit Breaker Security**: Circuit breaker state changes logged and require admin confirmation for manual reset
- **Monitoring Data Security**: Performance metrics anonymized and aggregated to prevent user behavior tracking

**Incident Response and Security Monitoring**:
- **Failed Operation Logging**: All database failures logged with sanitized query information (no user data in logs)
- **Suspicious Activity Detection**: Connection pool abuse and rapid failure patterns trigger security alerts
- **Data Breach Prevention**: Cache dump and export operations restricted to encrypted admin sessions only
- **Recovery Security**: Automated recovery operations validate user permissions before restoring service access
- **Compliance Requirements**: All security events logged for audit compliance with data retention policies

**Production Security Hardening**:
- **Environment Variable Security**: Database credentials and API keys stored in encrypted environment variables
- **Health Check Endpoint Security**: System health endpoints require authentication in production environment
- **Admin Dashboard Security**: Resilience dashboard accessible only via VPN or IP allowlist with MFA requirements
- **Error Message Sanitization**: User-facing error messages never expose internal database schema or connection details
- **Security Header Enforcement**: All resilience endpoints include security headers (HSTS, CSP, X-Frame-Options)

## Tasks / Subtasks

### Task 1: Core Resilient Database Client Implementation (AC: 1, 8, 10)
- [ ] **1.1 Enhanced Supabase Client with Connection Pooling** (4 hours)
  - [ ] Create `ResilientSupabaseClient` class with connection pool management
  - [ ] Implement connection pool with max 30 concurrent connections (safety buffer from 100 limit)
  - [ ] Add connection acquisition timeout (10s) and idle timeout (30s) configuration
  - [ ] Build connection health monitoring with real-time metrics collection
  - [ ] Unit tests for connection pool behavior under load with 95% coverage target
  
- [ ] **1.2 Exponential Backoff Retry Logic** (3 hours)
  - [ ] Implement retry mechanism with 1s, 2s, 4s, 8s exponential backoff sequence
  - [ ] Add jitter to retry delays to prevent thundering herd problems (±25% randomization)
  - [ ] Create configurable maximum retry attempts (default: 3) with per-operation override
  - [ ] Build retry context tracking for debugging and monitoring purposes
  - [ ] Unit tests for retry logic covering success, failure, and edge cases

- [ ] **1.3 Circuit Breaker Pattern Implementation** (3 hours)
  - [ ] Create `CircuitBreaker` class with CLOSED, OPEN, HALF_OPEN state management
  - [ ] Configure failure threshold (5 consecutive failures) and reset timeout (60 seconds)
  - [ ] Implement fast-fail behavior during OPEN state (<100ms response time)
  - [ ] Add circuit state monitoring and automatic recovery detection
  - [ ] Integration tests for circuit breaker behavior under various failure scenarios

- [ ] **1.4 Query Execution Wrapper with Timeout Management** (2 hours)
  - [ ] Build query timeout enforcement (30s complex, 5s simple queries)
  - [ ] Create query signature generation for monitoring and caching
  - [ ] Add performance metrics collection (execution time, rows affected, cache hits)
  - [ ] Implement query cancellation for timeout scenarios
  - [ ] Unit tests for timeout behavior and query execution monitoring

### Task 2: Comprehensive Caching Strategy & Read-Only Mode (AC: 2, 4, 10)
- [ ] **2.1 Multi-Tier Cache Manager Implementation** (5 hours)
  - [ ] Create `CacheManager` class with Redis primary and memory fallback
  - [ ] Implement cache key generation with user permission boundaries
  - [ ] Build TTL-based expiration with configurable policies (6hr-24hr based on data type)
  - [ ] Add cache warming for critical dashboard data and user analytics
  - [ ] Unit tests for cache operations, TTL behavior, and fallback scenarios

- [ ] **2.2 Read-Only Mode System Implementation** (4 hours)
  - [ ] Build system-wide read-only mode toggle with immediate UI updates
  - [ ] Create maintenance mode middleware with user-friendly error pages
  - [ ] Implement graceful write operation queuing during read-only mode
  - [ ] Add automatic read-only mode activation during critical database issues
  - [ ] Integration tests for read-only mode behavior across all user flows

- [ ] **2.3 Cache-First Data Serving Strategy** (3 hours)
  - [ ] Implement cache-first query strategy for analytics endpoints
  - [ ] Build cache invalidation patterns for data updates and user actions
  - [ ] Create cache hit/miss ratio monitoring with >95% target for dashboard queries
  - [ ] Add cache preloading for frequently accessed data patterns
  - [ ] Performance tests validating cache effectiveness under load

- [ ] **2.4 Fallback Data Provider System** (3 hours)
  - [ ] Create fallback data structures for offline/degraded mode operation
  - [ ] Implement stale-while-revalidate pattern for critical user data
  - [ ] Build cache invalidation coordination with database state changes
  - [ ] Add cache statistics and performance monitoring dashboard
  - [ ] Unit tests for cache invalidation and fallback data serving

### Task 3: Advanced Monitoring & Rate Limiting (AC: 3, 5, 10)
- [ ] **3.1 Real-Time Service Health Monitoring** (4 hours)
  - [ ] Create health check system for Supabase API, connections, and query performance
  - [ ] Build metrics collection for connection pool utilization, error rates, and response times
  - [ ] Implement automated alerts at 80% threshold for connections, bandwidth, and API calls
  - [ ] Create WebSocket-based real-time dashboard updates for admin monitoring
  - [ ] Integration tests for health monitoring accuracy and alert triggering

- [ ] **3.2 Intelligent Request Throttling System** (4 hours)
  - [ ] Implement per-user and system-wide request throttling based on subscription tier
  - [ ] Build adaptive throttling that responds to current Supabase service health
  - [ ] Create request queuing system with priority handling for premium users
  - [ ] Add throttling bypass for critical operations (health checks, admin functions)
  - [ ] Load tests validating throttling effectiveness at scale

- [ ] **3.3 Automated Scaling Alerts & Recommendations** (2 hours)
  - [ ] Build proactive alerting system for approaching service limits
  - [ ] Create upgrade recommendation engine based on usage patterns
  - [ ] Implement cost projection calculations for service tier upgrades
  - [ ] Add automated scaling preparation (connection pool adjustments, cache optimization)
  - [ ] Unit tests for alert logic and scaling recommendations

- [ ] **3.4 Performance Metrics Dashboard** (3 hours)
  - [ ] Create comprehensive admin dashboard for all resilience metrics
  - [ ] Build real-time charts for connection pool health, query performance, and error rates
  - [ ] Implement historical trend analysis for capacity planning
  - [ ] Add exportable reports for system performance analysis
  - [ ] E2E tests for dashboard functionality and data accuracy

### Task 4: Query Degradation & Error Handling (AC: 6, 9, 10)
- [ ] **4.1 Progressive Query Degradation Engine** (5 hours)
  - [ ] Create query complexity analyzer that categorizes queries by resource requirements
  - [ ] Implement progressive simplification: full -> simplified -> cached -> fallback
  - [ ] Build query rewriting rules for common analytics patterns
  - [ ] Add degradation decision tree based on current system health
  - [ ] Unit tests for query analysis and degradation logic

- [ ] **4.2 Intelligent Error Boundary System** (4 hours)
  - [ ] Create `DatabaseErrorBoundary` React component with multiple fallback strategies  
  - [ ] Implement error classification system for appropriate user messaging
  - [ ] Build retry mechanisms with user-controlled retry options
  - [ ] Add contextual error messages with actionable next steps
  - [ ] Component tests for error boundary behavior and user experience

- [ ] **4.3 User-Friendly Error Messaging System** (3 hours)
  - [ ] Create error message templates for different failure scenarios
  - [ ] Implement severity-based messaging (info, warning, error, critical)
  - [ ] Build error context enrichment with suggested user actions
  - [ ] Add error message localization framework for future internationalization
  - [ ] Unit tests for error message generation and context accuracy

- [ ] **4.4 Fallback Data Chain Implementation** (3 hours)
  - [ ] Build cascading fallback system: live -> cached -> simplified -> static
  - [ ] Create fallback data quality indicators for user transparency
  - [ ] Implement automatic fallback recovery when services return online
  - [ ] Add fallback performance tracking and optimization
  - [ ] Integration tests for complete fallback chain behavior

### Task 5: Dead Letter Queue & Recovery System (AC: 7, 10)
- [ ] **5.1 Failed Operation Queuing System** (4 hours)
  - [ ] Create `DeadLetterQueue` class for failed database operations
  - [ ] Implement operation metadata capture (query, params, user context, failure reason)
  - [ ] Build progressive retry scheduling (5min, 15min, 1hr, 6hr intervals)
  - [ ] Add operation deduplication to prevent duplicate processing
  - [ ] Unit tests for queue operations, retry scheduling, and deduplication

- [ ] **5.2 Intelligent Retry Processing Engine** (4 hours)
  - [ ] Implement background retry processor with configurable concurrency
  - [ ] Build retry success/failure tracking with detailed logging
  - [ ] Create retry prioritization based on operation type and user tier
  - [ ] Add automatic retry pause during system degraded states
  - [ ] Integration tests for retry processing under various system conditions

- [ ] **5.3 Admin Reconciliation Dashboard** (5 hours)
  - [ ] Build admin-only interface for failed operation management
  - [ ] Create manual retry controls with batch processing capabilities
  - [ ] Implement operation filtering and search functionality
  - [ ] Add audit trail for all manual interventions
  - [ ] E2E tests for admin dashboard functionality and security

- [ ] **5.4 Recovery Analytics & Reporting** (2 hours)
  - [ ] Create failure pattern analysis and trending reports
  - [ ] Build automated failure classification and root cause identification
  - [ ] Implement success rate tracking and improvement recommendations
  - [ ] Add recovery time analytics for performance optimization
  - [ ] Unit tests for analytics calculations and report generation

### Task 6: Production Monitoring & Health Dashboard (AC: 5, 8, 10)
- [ ] **6.1 Comprehensive Health Monitoring Dashboard** (6 hours)
  - [ ] Create real-time dashboard with connection pool, cache, and query health
  - [ ] Build system status visualization with traffic light indicators
  - [ ] Implement historical trend charts for capacity planning
  - [ ] Add drill-down capabilities for detailed performance analysis
  - [ ] Component tests for dashboard interactions and data visualization

- [ ] **6.2 Automated Alerting & Notification System** (3 hours)
  - [ ] Build email alert system for critical threshold breaches
  - [ ] Implement alert escalation based on severity and response time
  - [ ] Create alert suppression to prevent notification flooding
  - [ ] Add alert acknowledgment and resolution tracking
  - [ ] Integration tests for alert triggering and delivery

- [ ] **6.3 Performance Baseline & Anomaly Detection** (4 hours)
  - [ ] Implement performance baseline establishment using historical data
  - [ ] Build anomaly detection for unusual patterns in connection usage and query performance
  - [ ] Create predictive alerts for potential system issues
  - [ ] Add performance regression detection between deployments
  - [ ] Unit tests for baseline calculations and anomaly detection algorithms

- [ ] **6.4 Integration with External Monitoring** (2 hours)
  - [ ] Integrate with Sentry for error tracking and performance monitoring
  - [ ] Build custom metrics export for Vercel Analytics integration
  - [ ] Create health check endpoints for external monitoring services
  - [ ] Add custom event tracking for business impact measurement
  - [ ] Integration tests for external service connectivity and data export

### Task 7: Comprehensive Testing & Production Readiness (All ACs)
- [ ] **7.1 Advanced Integration Testing Suite** (8 hours)
  - [ ] Build comprehensive database outage simulation tests
  - [ ] Create cross-service integration tests with Stripe and Auth systems
  - [ ] Implement user journey tests during various failure scenarios
  - [ ] Add automated recovery testing for service restoration scenarios
  - [ ] Achieve 90% test coverage across all resilience components

- [ ] **7.2 Load & Stress Testing** (6 hours)
  - [ ] Create realistic load testing with 100+ concurrent users
  - [ ] Build connection pool stress tests at free tier limits
  - [ ] Implement sustained load testing for 24+ hour periods
  - [ ] Add chaos engineering tests for random failure injection
  - [ ] Validate performance benchmarks under load conditions

- [ ] **7.3 Security & Compliance Testing** (4 hours)
  - [ ] Implement security testing for admin operations and cache access
  - [ ] Build compliance tests for data retention and audit logging
  - [ ] Create penetration testing for resilience endpoints
  - [ ] Add data isolation tests for multi-user scenarios
  - [ ] Validate security controls under failure conditions

- [ ] **7.4 Production Deployment & Monitoring** (4 hours)
  - [ ] Create production deployment checklist and rollback procedures
  - [ ] Build production health monitoring with alerting configuration
  - [ ] Implement gradual feature rollout with kill switches
  - [ ] Add production data migration for new resilience tables
  - [ ] Create operational runbooks for common failure scenarios

- [ ] **7.5 Documentation & Team Training** (3 hours)
  - [ ] Update architectural documentation with resilience patterns
  - [ ] Create operational guides for monitoring and troubleshooting
  - [ ] Build administrator training materials for resilience dashboard
  - [ ] Add API documentation for health and monitoring endpoints
  - [ ] Create incident response playbooks for various failure scenarios

## Project Structure Notes

**Comprehensive Architecture Integration** [Source: architecture/source-tree.md]

**Core Library Extensions**:
- Resilience system naturally extends `/src/lib/` with specialized database management utilities
- Connection pooling and circuit breaker patterns follow established utility function organization
- Cache management integrates with existing data layer patterns in `/src/lib/database.ts`
- Monitoring utilities complement existing `/src/lib/utils.ts` and validation patterns

**Component Architecture Alignment**:  
- Health monitoring dashboards fit seamlessly into `/src/components/features/` feature-based organization
- UI components for error boundaries and status indicators extend `/src/components/ui/` reusable component library
- Admin interfaces align with protected route patterns and authentication component structure
- Real-time monitoring components leverage existing React patterns and state management

**API Endpoint Expansion**:
- System health endpoints naturally extend `/src/app/api/` REST API structure
- Admin routes follow established authentication and authorization patterns
- Monitoring APIs integrate with existing error handling and response formatting
- Health check endpoints complement existing analytics and subscription API patterns

**Enhanced Testing Strategy**:
- Resilience testing extends `/__tests__/` organization with specialized integration and load test suites
- Unit tests align with established Jest and React Testing Library patterns
- End-to-end tests integrate with existing user journey testing framework
- Chaos engineering tests introduce advanced testing patterns while maintaining existing test infrastructure

**Cross-Story Integration Architecture**:

**Story 2.1 (NextAuth) Integration**:
- Session-aware connection pooling leverages existing JWT token validation
- User context preservation during database failures maintains authentication state
- Admin operation security builds upon established role-based access patterns

**Story 2.4 (Rate Limiting) Coordination**:
- Unified Redis caching strategy coordinates with rate limiting cache keys
- Throttling mechanisms share middleware patterns and request queue management
- Cache invalidation patterns coordinate between rate limiting and database caching

**Story 2.5 (Stripe Failure Handling) Coordination**:
- Dead letter queue patterns unify database and payment failure recovery
- Exponential backoff strategies maintain consistent retry behavior across services
- Circuit breaker patterns coordinate between database and payment service health

**Story 2.2 (Stripe Integration) Support**:
- Subscription status caching ensures payment processing availability during database issues
- User tier validation remains functional during degraded database mode
- Premium user prioritization extends to connection pool and cache resource allocation

**Scalability and Maintenance Considerations**:
- Monitoring infrastructure scales with existing Vercel Analytics and Sentry integration
- Performance baselines integrate with existing analytics data pipeline
- Operational procedures align with established deployment and monitoring practices
- Documentation patterns follow existing architectural documentation standards

**Bangkok Dataset Optimization Integration**:
- Connection pooling optimized for 134 sensors × 7 floors = 938 sensor data patterns
- Cache strategies prioritized for 3.2M sensor reading query optimization
- Query degradation specifically tuned for time-series analytics workload patterns
- Materialized view caching aligned with existing dashboard performance requirements

**Production Readiness & Operations**:
- Monitoring dashboards integrate with existing admin interface patterns
- Alert systems coordinate with established notification and escalation procedures
- Backup and recovery procedures complement existing data protection strategies
- Performance optimization aligns with existing analytics query optimization patterns

**No Architectural Conflicts** - All resilience enhancements maintain backward compatibility with existing codebase architecture while providing comprehensive failure handling and performance optimization for the CU-BEMS IoT platform.